{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "* Tensor are basic data structure of Machine Learning\n",
    "* It's almost always numerical data\n",
    "* Tensor are basically a container for number.\n",
    "* Tensors are generalization of matrics to an arbitrary number of dimension (in tensor a _dimension is called an _axis_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Tensor:\n",
    "1. Scalars (0D tensor) : In Numpy `float32` & `float64` number is scalar tensor\n",
    "2. Vectors (1D tensor) : They have only one axis\n",
    "3. Matices (2D tensor) : They have two axes (rows and columns)\n",
    "4. 3D tensor and higher-dimensional tensors : By packing (n-1)D _(Eg. 3d)_ in arrays we can make nD tensor _(i.e 4d)_. \n",
    "\n",
    "**Note**: X = [1,2,3,4,5] is a _5-dimensional vector_ NOT _5-dimensional tensor_ rather _1-dimensional tensor_. Technically a 5D tensor can be called _a tensor of rank 5_ (the rank of tensor being the number of axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Scalars: 0\n",
      "Dimension of Vectors: 1\n",
      "Dimension of Matrices: 2\n",
      "Dimension of 3D tensor: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Dimension of Scalars:\", np.array(1).ndim)\n",
    "print(\"Dimension of Vectors:\", np.array([1,2,3]).ndim)\n",
    "print(\"Dimension of Matrices:\", np.array([[1,2,3],\n",
    "                                          [1,2,3]]).ndim)\n",
    "print(\"Dimension of 3D tensor:\", np.array([[[1,2,3], [1,2,3]],\n",
    "                                           [[1,2,3], [1,2,3]]]).ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep learning, we’ll generally manipulate tensors that are 0D to 4D , although you may go up to\n",
    "5D if we process video data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key attribute of a tensor\n",
    "A tensor is defined by three key attributes:\n",
    "* _Number of axes (rank)_---For instance, a 3D tensor has rank 3 and a 2D tensor has only 2. In Python it's called `nidm`. \n",
    "* _Shape_---This is a tuple of integers that describes how many dimensions the tensor has along each axis. For example a 3D tensor has a shape of (3,3,2).\n",
    "* _Data type (usually called `dtype` in Python libraries)_ ---This is the type of the data contained in the tensor; for instance, a tensor’s type could be float32 , uint8 , float64 , and so on. On rare occasions, you may see a char tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank:  3\n",
      "shape:  (60000, 28, 28)\n",
      "dtype:  uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"rank: \", train_images.ndim)\n",
    "print(\"shape: \", train_images.shape)\n",
    "print(\"dtype: \", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 8 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor slicing\n",
    "* electing elements in tensor is called _tensor slicing_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crop images to patches of 14 × 14 pixels centered in the middle\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the nth batch of images dataset\n",
    "n = 5\n",
    "batch = train_images[128 * n:128 * (n+1)]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering a batch tensor, the first axis (axis 0) is called the batch axis or\n",
    "batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real World example of Data Tensors\n",
    "* Vector data— 2D tensors of shape `(samples, features)`\n",
    "* Timeseries data or sequence data— 3D tensors of shape `(samples, timesteps, features)`\n",
    "* Images— 4D tensors of shape `(samples, height, width, color_channels)` (in _Tensorflow_) or `(samples, color_channels, height, width)` (in _Theano_)\n",
    "* Video— 5D tensors of shape `(samples, frames, height, width, channels)` or `(samples, frames, channels, height, width)`\n",
    "    * For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames per\n",
    "second would have 240 frames. A batch of four such video clips would be stored in a\n",
    "tensor of shape (4, 240, 144, 256, 3) . That’s a total of 106,168,320 values! If the\n",
    "dtype of the tensor was float32 , then each value would be stored in 32 bits, so the\n",
    "tensor would represent 405 MB. Heavy! Videos you encounter in real life are much\n",
    "lighter, because they aren’t stored in float32 , and they’re typically compressed by a\n",
    "large factor (such as in the MPEG format)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
