{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "            input_length=max_len,\n",
    "            name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    # Interrupts training when improvement stops\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='acc', # Monitor model's validation accuracy\n",
    "        patience=1, # Interrupt training when accuracy has stopped improving for more than 1 epochs\n",
    "    ),\n",
    "    # Save current weight after each epoch\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5', # Path\n",
    "        monitor='val_loss', # Save only if val loss is better than previous\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 17s 664us/step - loss: 0.5748 - acc: 0.7301 - val_loss: 0.4392 - val_acc: 0.8101\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 15s 617us/step - loss: 0.4743 - acc: 0.7386 - val_loss: 0.4882 - val_acc: 0.7256\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 16s 642us/step - loss: 0.4590 - acc: 0.6383 - val_loss: 0.5283 - val_acc: 0.6350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1033baada0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         epochs=10,\n",
    "         batch_size=32,\n",
    "         callbacks=callbacks_list,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Keras Callbacks.ipynb'   my_model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    # Reduce the LR\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', # Monitors the model's validation loss\n",
    "        factor=0.1, # Divide LR by 10 times when triggred\n",
    "        patience=10, # callback is triggered after the validation loss has stopped improving for 10 epochs.\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 14s 577us/step - loss: 0.3729 - acc: 0.5742 - val_loss: 0.6348 - val_acc: 0.5605\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 15s 583us/step - loss: 0.3169 - acc: 0.4904 - val_loss: 0.8422 - val_acc: 0.4199\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 15s 589us/step - loss: 0.2641 - acc: 0.4008 - val_loss: 0.9213 - val_acc: 0.3482\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 15s 597us/step - loss: 0.2308 - acc: 0.2924 - val_loss: 1.2992 - val_acc: 0.2993\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 15s 593us/step - loss: 0.2156 - acc: 0.1989 - val_loss: 1.3376 - val_acc: 0.2174\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 15s 607us/step - loss: 0.2086 - acc: 0.1632 - val_loss: 1.3850 - val_acc: 0.1860\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 15s 617us/step - loss: 0.2028 - acc: 0.1182 - val_loss: 1.5217 - val_acc: 0.1482\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 15s 605us/step - loss: 0.2004 - acc: 0.0914 - val_loss: 1.5150 - val_acc: 0.1356\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 15s 608us/step - loss: 0.2005 - acc: 0.0777 - val_loss: 1.4648 - val_acc: 0.1343\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 16s 625us/step - loss: 0.2001 - acc: 0.0633 - val_loss: 1.5324 - val_acc: 0.1173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10339872e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         epochs=10,\n",
    "         batch_size=32,\n",
    "         callbacks=callbacks_list,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a custom callback that saves to disk (as Numpy arrays) the\n",
    "activations of every layer of the model at the end of every epoch, computed on the\n",
    "first sample of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_output = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,\n",
    "                                                   layer_output)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'wb')\n",
    "        np.savez(f, *activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [ActivationLogger()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 24s 965us/step - loss: 0.2041 - acc: 0.0186 - val_loss: 1.7907 - val_acc: 0.0647\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 21s 835us/step - loss: 0.2045 - acc: 0.0172 - val_loss: 1.8560 - val_acc: 0.0647\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 32s 1ms/step - loss: 0.1915 - acc: 0.0186 - val_loss: 1.8072 - val_acc: 0.0592\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.1922 - acc: 0.0168 - val_loss: 1.8205 - val_acc: 0.0573\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.1930 - acc: 0.0171 - val_loss: 1.8526 - val_acc: 0.0574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1033a037b8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         epochs=5,\n",
    "         batch_size=32,\n",
    "         callbacks=callbacks_list,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activations_at_epoch_0.npz   activations_at_epoch_3.npz   my_model.h5\r\n",
      " activations_at_epoch_1.npz   activations_at_epoch_4.npz\r\n",
      " activations_at_epoch_2.npz  'Keras Callbacks.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.05784114  0.03194386  0.06401597 ...  0.00056683 -0.04904091\n",
      "   -0.03265695]\n",
      "  [-0.05784114  0.03194386  0.06401597 ...  0.00056683 -0.04904091\n",
      "   -0.03265695]\n",
      "  [-0.05784114  0.03194386  0.06401597 ...  0.00056683 -0.04904091\n",
      "   -0.03265695]\n",
      "  ...\n",
      "  [-0.02606118  0.11000165  0.00628612 ... -0.058791   -0.02768152\n",
      "    0.00669897]\n",
      "  [ 0.10527123 -0.01816737  0.01716958 ...  0.03317714  0.03957639\n",
      "    0.03021466]\n",
      "  [ 0.03561759 -0.12553193  0.01477517 ...  0.08704042  0.01571502\n",
      "   -0.1405469 ]]]\n"
     ]
    }
   ],
   "source": [
    "activations_at_epoch_0 = np.load('activations_at_epoch_0.npz')\n",
    "print(activations_at_epoch_0['arr_0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
