{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualizing heatmaps of class activation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5ePhpJaAYSVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a91dae87-0d61-4efc-f700-a61503076d46"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "dAnY1abwYSVo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing heatmaps of class activation\n",
        "\n",
        "It is useful for understanding whihc parts of a given image led a convnet to its final classification decision.\n",
        "\n",
        "This general category of techniques is called \"Class Activation Map\" (CAM) visualization, and consists in producing heatmaps of \"class activation\" over input images. A \"class activation\" heatmap is a 2D grid of scores associated with an specific output class, computed for every location in any input image, indicating how important each location is with respect to the class considered. For instance, given a image fed into one of our \"cat vs. dog\" convnet, Class Activation Map visualization allows us to generate a heatmap for the class \"cat\", indicating how cat-like different parts of the image are, and likewise for the class \"dog\", indicating how dog-like differents parts of the image are."
      ]
    },
    {
      "metadata": {
        "id": "0Rq84DChYSVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eb7a7c66-b7ab-4fe8-ee87-16ca7d49b72c"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "model = VGG16(weights='imagenet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J_jEcQQBYSV2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's consider the following image of two African elephants, possible a mother and its cub, strolling in the savanna.\n",
        "\n",
        "\n",
        "![elephants](https://s3.amazonaws.com/book.keras.io/img/ch5/creative_commons_elephant.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "958-s8kpYSV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's convert this image into something the VGG16 model can read: the model was trained on images of size 244x244, preprocessed according to a few rules that are packaged in the utility function `keras.applications.vgg16.preprocess_input`. So we need to load the image, resize it to 244x244, convert it to a Numpy float32 tensor, and apply these pre-processing rules."
      ]
    },
    {
      "metadata": {
        "id": "e-N1afZ9YSV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# The local path to our target image\n",
        "img_path = 'creative_commons_elephant.jpg'\n",
        "\n",
        "# `img` is a PIL image of size 224x224\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "# `x` is a float32 Numpy array of shape (224, 224, 3)\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# We add a dimension to transform our array into a \"batch\"\n",
        "# of size (1, 224, 224, 3)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Finally we preprocess the batch\n",
        "# (this does channel-wise color normalization)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulIlUZQJYSWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0f779984-fc85-427f-d948-e765f0d16b2f"
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print('Predicted: ', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 1us/step\n",
            "Predicted:  [('n02504458', 'African_elephant', 0.9094207), ('n01871265', 'tusker', 0.08618318), ('n02504013', 'Indian_elephant', 0.0043545896)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tRwuhXjaaIUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our network has recognized our image as containing an indetermined quality of African elephants. The entry in the prediction vector that was maximally activated is the one corresponding to the \"African elephant\" class, at index 386:"
      ]
    },
    {
      "metadata": {
        "id": "5bNqAo4FYSWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "532c35a5-5de6-472b-9d63-9870c85ddcae"
      },
      "cell_type": "code",
      "source": [
        "np.argmax(preds[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Rh1a2RYSYSWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up Grad-CAM process\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# This is the \"african elephant\" entry in the prediction vector\n",
        "african_elephant_output = model.output[:, 386]\n",
        "\n",
        "# The is the output feature map of the `block5_conv3` layer,\n",
        "# the last convolutional layer in VGG16\n",
        "last_conv_layer = model.get_layer('block5_conv3')\n",
        "\n",
        "# This is the gradient of the \"african elephant\" class with regard to\n",
        "# the output feature map of `block5_conv3`\n",
        "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
        "\n",
        "# This is a vector of shape (512,), where each entry\n",
        "# is the mean intensity of the gradient over a specific feature map channel\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "# This function allows us to access the values of the quantities we just defined:\n",
        "# `pooled_grads` and the output feature map of `block5_conv3`,\n",
        "# given a sample image\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "# These are the values of these two quantities, as Numpy arrays,\n",
        "# given our sample image of two elephants\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "# We multiply each channel in the feature map array\n",
        "# by \"how important this channel is\" with regard to the elephant class\n",
        "for i in range(512):\n",
        "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "\n",
        "# The channel-wise mean of the resulting feature map\n",
        "# is our heatmap of class activation\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PK2vG_-JbSFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "2f4951c2-e76c-42d2-c59d-f4a44eff3c38"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.matshow(heatmap, cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAFSCAYAAABPFzzRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAF75JREFUeJzt3X9w1PWdx/HXZjcBE36FaKChElKu\nLa0ch/acMwj+GBKQ6em0OEBMQZna8QeidIoVzOhBLyc2HHZAtIKgtEMajVJUZq4SwDFX7ibYUad4\neKf8VgwQfiUEEkLI7t4f1+ZESb4/eH+zu/h8/KWb9/e7r9nsvvzuup98QvF4PC4AwEVJS3QAALgU\nUKYAYIAyBQADlCkAGKBMAcAAZQoABpKqTBctWqRp06appKREH3zwQaLjOFq8eLGmTZum22+/XZs2\nbUp0HFfa2tpUVFSk9evXJzqKow0bNui2227T5MmTVVtbm+g4XWppadHs2bM1Y8YMlZSUaOvWrYmO\n1KWdO3eqqKhIlZWVkqRDhw5pxowZKi0t1Zw5c9Te3p7ghOe7UN6ZM2dq+vTpmjlzpo4ePZrghP8v\nacr0T3/6kz755BNVV1friSee0BNPPJHoSN3atm2bdu3aperqaq1evVqLFi1KdCRXnnvuOfXv3z/R\nMRw1Njbq2WefVVVVlVasWKG33nor0ZG69Nprr6mgoEBr167VsmXLkva529raqvLychUWFnbe9vTT\nT6u0tFRVVVXKz8/XunXrEpjwfBfKu3TpUk2dOlWVlZUqLi7WmjVrEpjwfElTpnV1dSoqKpIkDR8+\nXCdPntTp06cTnKpr1157rZYtWyZJ6tevn86cOaNoNJrgVN3bs2ePdu/erZtuuinRURzV1dWpsLBQ\nffr0UW5ursrLyxMdqUvZ2dlqamqSJDU3Nys7OzvBiS4sIyNDq1atUm5ubudt77zzjsaPHy9Juvnm\nm1VXV5eoeF9yobwLFizQxIkTJZ3/uCeDpCnTY8eOnfckHDhwYFJdwn9ROBxWZmamJGndunW64YYb\nFA6HE5yqexUVFZo/f36iY7jy2Wefqa2tTffdd59KS0uT6kX+Rd///vd18OBBFRcXa/r06Zo3b16i\nI11QJBJR7969z7vtzJkzysjIkCTl5OQk1WvuQnkzMzMVDocVjUZVVVWlW2+9NUHpviyS6ABdSZVV\nrlu2bNG6dev04osvJjpKt15//XWNHj1aV155ZaKjuNbU1KRnnnlGBw8e1J133qm3335boVAo0bG+\n5I033lBeXp5eeOEFffTRRyorK0uJz6S/KFVec9FoVI888oiuu+668z4CSLSkKdPc3FwdO3as89+P\nHDmiK664IoGJnG3dulUrVqzQ6tWr1bdv30TH6VZtba0OHDig2tpaHT58WBkZGRo8eLDGjBmT6GgX\nlJOTo6uvvlqRSERDhw5VVlaWTpw4oZycnERH+5L3339fY8eOlSSNGDFCR44cUTQaTfp3KtL/Xem1\ntbWpd+/eamhoOO8tdbJ69NFHlZ+fr9mzZyc6ynmS5m3+9ddfr5qaGknShx9+qNzcXPXp0yfBqbp2\n6tQpLV68WCtXrtSAAQMSHcfR0qVL9fvf/16vvPKKpkyZolmzZiVtkUrS2LFjtW3bNsViMTU2Nqq1\ntTVpP4vMz8/X9u3bJUn19fXKyspKiSKVpDFjxnS+7jZt2qRx48YlOFH3NmzYoPT0dD300EOJjvIl\noWT6q1FLlizRu+++q1AopAULFmjEiBGJjtSl6upqLV++XAUFBZ23VVRUKC8vL4Gp3Fm+fLmGDBmi\nyZMnJzpKt15++eXO/7t8//33d/6PkmTT0tKisrIyHT9+XB0dHZozZ05Svf38qx07dqiiokL19fWK\nRCIaNGiQlixZovnz5+vs2bPKy8vTk08+qfT09ERHlXThvMePH1evXr06L7SGDx+uhQsXJjboXyRV\nmQJAqkqat/kAkMooUwAwQJkCgAHKFAAMUKYAYIAyBQADlCkAGKBMAcBAj6zNvyXnHtezK/5jge4b\n+wtXs/GzZ/1G6lYoK8v17Ip/f0z33fgvgeRwraPD9aiXxzfa2Og3kZnnP3hK94ya6ziX5uF35kVa\nP29/c+G5tx7V/eOfdJyLx2J+I3XP42tixX/+Qvddv8B5MBTQdVea+z9cs+KP/6T7bvhnd8MDg1ni\nvfHjii5/lnRXpsO+MyTRETwZNiL5l49+Xqo9vgUjhyY6gic8H4KT7FmTrkwBIBVRpgBggDIFAAOU\nKQAYoEwBwIDvr0YtWrRI27dvVygUUllZmUaNGmWZCwBSiq8y/fwe93v27FFZWZmqq6utswFAyvD1\nNj/V9rgHgKD5KtNU2+MeAILmaw+oxx9/XDfeeGPn1ekdd9yhRYsWnbe53Oft/5/6pF+9AAAXw9dn\npl73uHe7FlySNh5/3vVa/mRYm7+x4de6ZdCsQHK45mFtvpfHNxnW5m+OvaritCmOc8myNv/N+uWa\nNORBx7lkWZu/8cRq3TLwJ86DSbA2f+PRlbrlinvdDafK2vxU2+MeAILm68r0mmuu0VVXXaWSkpLO\nPe4B4KvM9/dMH374YcscAJDSWAEFAAYoUwAwQJkCgAHKFAAMUKYAYIAyBQADPbI7qdeVSm7nY62t\nfuI4CrW3e5qPuVwpFI9G/cRxcWJvK4LdrmxKy8z0k6ZbQf3OYi0tSXPejkOHHWfC/fr5ieMsI937\nMREXNdB+zvt5XYh3eHvuxl3mCDUccx4yxpUpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAMUKYAYIAy\nBQADlCkAGKBMAcAAZQoABihTADBAmQKAAcoUAAxQpgBggDIFAAOUKQAYoEwBwABlCgAGKFMAMECZ\nAoCBHtmdNC17QDDz4bCPNC543EU0lJERyHld37/Hx8HtrqNB7CQacrMTpo9jotf/rZ84jjIOuNvJ\n9fMi3xjmONNxeV8faZyFG33s0prd33kmEsxrLe2Mt52L03KyXc3F03uk2s7DlSkAGKBMAcAAZQoA\nBihTADBAmQKAAcoUAAz4/v7A4sWL9d5776mjo0P33nuvJkyYYJkLAFKKrzLdtm2bdu3aperqajU2\nNuqHP/whZQrgK81XmV577bUaNWqUJKlfv346c+aMotGowkF9iR4Akpyvz0zD4bAy/7KKZt26dbrh\nhhsoUgBfaaF4PB73e/CWLVu0cuVKvfjii+rbt+vlcfs/PqRh3/6a37sBgKTnu0y3bt2qZcuWafXq\n1RowoPu19JOunOP6vG8eWOZ6PtZ8yvV5PfGwhr7m9G81sc9drmbjSbA230veZFibv6n9JU3IuMNx\nLlnW5r+5+1816W9+7jiXLGvzN35coVu+Pc95MKC1+SEPa/Pf3PuUJn1jrqvZoNbmb/y4osuf+brH\nU6dOafHixfrNb37jWKQA8FXgq0z/8Ic/qLGxUT/96U87b6uoqFBeXp5ZMABIJb7KdNq0aZo2bZp1\nFgBIWayAAgADlCkAGKBMAcAAZQoABihTADBAmQKAgZ7Zwq+Xy907Pc6HwsH8tyDW5m3HxPi5Dndz\nHef8xHEUuuyyYM6b7vH35kLasK97P6ZgqONMS459VkkKdXhflHLua87HpO855CeOo46GI56Pie7e\n5zgTGRLMd8hjA72tBIv1c7mzbmYwz4fucGUKAAYoUwAwQJkCgAHKFAAMUKYAYIAyBQADlCkAGKBM\nAcAAZQoABihTADBAmQKAAcoUAAxQpgBggDIFAAOUKQAYoEwBwABlCgAGKFMAMECZAoAByhQADFCm\nAGCgZ3YnjceDnTcWSvf2sLidT+vvbSdGt86OGuZpvv2677iaO3NFuo803TuXGfJ8zNGxgxxnTvxd\nMM+ZWP+w52N2/cT5mN77hvuJ4+iyI9/wfMzRe69znAkF9JIcsKvd03z75Vmu5qK9ev46kStTADBA\nmQKAAcoUAAxQpgBggDIFAAOUKQAYuKgybWtrU1FRkdavX2+VBwBS0kWV6XPPPaf+/ftbZQGAlOW7\nTPfs2aPdu3frpptuMowDAKnJd5lWVFRo/vz5llkAIGWF4nHvazdff/11HTx4ULNmzdLy5cs1ZMgQ\nTZ48ucv5/TsPa9i3Bl9UUABIZr7W5tfW1urAgQOqra3V4cOHlZGRocGDB2vMmDEXnL9/0hLX535z\nzxJNGv6wq9l4Y5Pr83oRbz/nerbm9G81sc9drmZDmZf5jdQtL2vz394yXzcX/dLVbDKszX/vhZ/p\ne3f/ynEuuLX57p8LkvTJXfOV/1vnx7f3vl5+I3XrsiPeHoc///pnGj3L+fFNhrX5Xp67Qa3N/+O/\nPdLlz3yV6dKlSzv/+a9Xpl0VKQB8FfA9UwAwcNF/gu/BBx+0yAEAKY0rUwAwQJkCgAHKFAAMUKYA\nYIAyBQADlCkAGOiR3UljhxoCmQ9lZfqJ43zeYc67YZ4//3VXcwf+8XLvYVw4/W1vOzzu/ZG7VUjp\nWa1+4nQrVu/9d9Y40sXym4BW6IROe3+JuDnmXN9gAoei3nd/bctxPubyDzv8xHGU3tgWyHx62Pvj\ncLG4MgUAA5QpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAMUKYAYIAyBQADlCkAGKBMAcAAZQoABihT\nADBAmQKAAcoUAAxQpgBggDIFAAOUKQAYoEwBwABlCgAGKFMAMNAzu5O2eduB0PX82bM+0jgLDf2a\np/lYr3RXcz//8St+4ji6s98xD9PztG/SaleTU/eO9xeoG/s3fsvzMQP/y3mnyV7NMT9xHHX09rjL\n5QPSoDrnY/rut9/5VZIijR7PWy4NW3/UcSzat7fPRN0LRaOBzKedaPET56JwZQoABihTADBAmQKA\nAcoUAAxQpgBggDIFAAO+y3TDhg267bbbNHnyZNXW1hpGAoDU46tMGxsb9eyzz6qqqkorVqzQW2+9\nZZ0LAFKKry/t19XVqbCwUH369FGfPn1UXl5unQsAUkooHo/HvR70/PPPa+/evWpqalJzc7MefPBB\nFRYWdjm/b8enKhg59KKCAkAy872ctKmpSc8884wOHjyoO++8U2+//bZCoQsvo7tn1FzX590ce1XF\naVPcDXdxfxcrNPq7rmc3vbdQE7630NVs6Us1PhN1z8ty0rTBuxQ7/E1Xs4EsJ13tbTnpuy/+TH//\n4185ziXLctJ3KufqH6Y/5TjXd/8Zv5G65XU56cYPF+mWq8oc54JaTprWds71bM2fyzVx9OPuznsy\nmOWkb+7r+rno6zPTnJwcXX311YpEIho6dKiysrJ04sQJ3wEBINX5KtOxY8dq27ZtisViamxsVGtr\nq7Kzs62zAUDK8PU2f9CgQZo4caKmTp0qSXrssceUlsZXVgF8dfn+zLSkpEQlJSWWWQAgZXE5CQAG\nKFMAMECZAoAByhQADFCmAGCgRzbUC0paZmYw5z120tN82OX8wi23+4njqHyg+40F95RI36yd6Wo2\netR+1Ut2hvdjoi6OST/tbWM2t+KhsOdjwmedV2hHdh30E8fZuXbvxxw64jiSFva2yaRbsT7enhCx\nTHfzaaeCWWHW7X32+D0CwCWIMgUAA5QpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAMUKYAYIAyBQAD\nlCkAGKBMAcAAZQoABihTADBAmQKAAcoUAAxQpgBggDIFAAOUKQAYoEwBwABlCgAGUnp30lhLSzDn\nbW31NN/xWb2ruW+t6e8njqNTw/u6Hy6Rcl93t+toLIBnRyjmvHPnF/Vqdj6m47Jgrgv6fuxtp1q3\nx8Tb2vzEcRRr8fbclaRo82nHmfDho37iOIr07eNtvsHd7yOe3vPVxpUpABigTAHAAGUKAAYoUwAw\nQJkCgAHKFAAMUKYAYMDXl7FaWlo0b948nTx5UufOndMDDzygcePGWWcDgJThq0xfe+01FRQUaO7c\nuWpoaNBdd92ljRs3WmcDgJTh621+dna2mpqaJEnNzc3Kzs42DQUAqSYUj8e9r++TdPfdd+vTTz9V\nc3OzVq5cqdGjR3c5u2/HpyoYOdR3SABIdr7e5r/xxhvKy8vTCy+8oI8++khlZWVav359l/P3jJrr\n+tybY6+qOG2Kn1h2QiHXo5ujr6g4PNXdaa/5rt9E3fKyNr/u5bkqLHnK1Wwwa/O9zW+rmqvrSp3z\nRs54PLFLWXuaPc3XfFCuiaMedx78xN3fc/DK69r8zR0vqzhS4jgXHjjAb6RuhTyszX9zzxJNGv6w\nq9mg1uZv/OiXXf7M19v8999/X2PHjpUkjRgxQkeOHFE0GvWXDgAuAb7KND8/X9u3b5ck1dfXKysr\nS+Fw2DQYAKQSX9fC06ZNU1lZmaZPn66Ojg4tXLjQOBYApBZfZZqVlaVly5ZZZwGAlMUKKAAwQJkC\ngAHKFAAMUKYAYIAyBQADKb07aWC8rrB1OR9//799hHE2oDHf2/y7h13NtQ+x/5sL8Yj71WV/ldnQ\n7jiT0eC8w6Yf8b2fej9o937HkVhAu5P6EnNecBM9djyY+/Z43o59nwSTwwBXpgBggDIFAAOUKQAY\noEwBwABlCgAGKFMAMECZAoAByhQADFCmAGCAMgUAA5QpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAM\nUKYAYIAyBQADlCkAGKBMAcAAZQoABtidtCd53fXUpY69+wOZDx846D2Mk3jM8yGRrR84zkQ7Ovyk\nCURS7TyKHsOVKQAYoEwBwABlCgAGKFMAMECZAoAByhQADLgq0507d6qoqEiVlZWSpEOHDmnGjBkq\nLS3VnDlz1N7eHmhIAEh2jmXa2tqq8vJyFRYWdt729NNPq7S0VFVVVcrPz9e6desCDQkAyc6xTDMy\nMrRq1Srl5uZ23vbOO+9o/PjxkqSbb75ZdXV1wSUEgBTguAIqEokoEjl/7MyZM8rIyJAk5eTk6OjR\no8GkA4AUcdHLSeMulkg+/8FTKhg51PU5N8devZhIPY68wdrU/lKiI3iSao9vKuVN5qy+yjQzM1Nt\nbW3q3bu3GhoazvsI4ELuGTXX9bk3x15VcdoUP7ES4lLOG0rPsA/gcW3+pvaXNCHjDufTJsna/Ev5\n+ZBoyZC1uzL39dWoMWPGqKamRpK0adMmjRs3zl8yALhEOF6Z7tixQxUVFaqvr1ckElFNTY2WLFmi\n+fPnq7q6Wnl5efrBD37QE1kBIGk5lunIkSO1du3aL92+Zs2aQAIBQCpiBRQAGKBMAcAAZQoABihT\nADBAmQKAAcoUAAyk9u6koVAwp42ke5t3uVIofi61/lRhsuRNltVNSCEBdUN3uDIFAAOUKQAYoEwB\nwABlCgAGKFMAMECZAoAByhQADFCmAGCAMgUAA5QpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAMUKYA\nYIAyBQADlCkAGKBMAcAAZQoABihTADDQI7uTut290+t8PBr1E8f8vEHluCSlhQM5JhT2cV434jHP\nh4Qizi+reCzuJ00wEvj4en7tuHz+BPZ86AZXpgBggDIFAAOUKQAYoEwBwABlCgAGKFMAMOCqTHfu\n3KmioiJVVlZKkg4dOqSZM2dq+vTpmjlzpo4ePRpoSABIdo5l2traqvLychUWFnbetnTpUk2dOlWV\nlZUqLi7WmjVrAg0JAMnOsUwzMjK0atUq5ebmdt62YMECTZw4UZKUnZ2tpqam4BICQApwLNNIJKLe\nvXufd1tmZqbC4bCi0aiqqqp06623BhYQAFJBKB6Pu1rXtnz5cmVnZ2v69OmSpGg0qkceeUQFBQWa\nPXt2t8fu//CAhl115cWnBYAk5Xtt/qOPPqr8/HzHIpWke66Z7/q8m87+ThN6/cjVbDKsid/c8bKK\nIyXuhmNJkDf2qorTpiQugMe1+W4f32RZm7+p/SVNyLjDxWmTY21+oh9fL69hL6+1oPJuOvu7Ln/m\n66tRGzZsUHp6uh566CHfoQDgUuJ4Zbpjxw5VVFSovr5ekUhENTU1On78uHr16qUZM2ZIkoYPH66F\nCxcGnRUAkpZjmY4cOVJr167tiSwAkLJYAQUABihTADBAmQKAAcoUAAxQpgBggDIFAAM9sjtp/Fx7\noPMJlwQrm1KGn8fKxTHxJPodxDs6EnfnoZD3Y1ys8op3eN+l1d19e1wJ5vL3nIjnA1emAGCAMgUA\nA5QpABigTAHAAGUKAAYoUwAwQJkCgAHKFAAMUKYAYIAyBQADlCkAGKBMAcAAZQoABihTADBAmQKA\nAcoUAAxQpgBggDIFAAOUKQAYoEwBwABlCgAGQvG41+0BAQBfxJUpABigTAHAAGUKAAYoUwAwQJkC\ngAHKFAAM/C/QijiJZedcoQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb2422447f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GCzK6n36biwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0a167bd-f449-4460-9ad9-adafd26cebfd"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# We use cv2 to load the original image\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# We resize the heatmap to have the same size as the original image\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "# We convert the heatmap to RGB\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "# We apply the heatmap to the original image\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "# 0.4 here is a heatmap intensity factor\n",
        "superimposed_img = heatmap * 0.4 + img\n",
        "\n",
        "# Save the image to disk\n",
        "cv2.imwrite('elephant_cam.jpg', superimposed_img)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "obsrHdeqcF_P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![elephant cam](https://s3.amazonaws.com/book.keras.io/img/ch5/elephant_cam.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "d6X1OYHPcN2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This visualisation technique answers two important questions:\n",
        "\n",
        "  *  Why did the network think this image contained an African elephant?\n",
        " *   Where is the African elephant located in the picture?\n",
        "\n",
        "In particular, it is interesting to note that the ears of the elephant cub are strongly activated: this is probably how the network can tell the difference between African and Indian elephants.\n"
      ]
    }
  ]
}